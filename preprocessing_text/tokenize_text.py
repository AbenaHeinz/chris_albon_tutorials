# load libary  
from nltk.tokenize import word_tokenize, sent_tokenize

# create text  
string = "The science of today is the technology tomorrow. Tomorrow is today."

#Tokenize words  
word_tokenize(string)

# tokenized sentence 
sent_tokenizer(string)